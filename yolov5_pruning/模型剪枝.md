深度学习模型的压缩和加速是指利用神经网络参数的冗余性和网络结构的冗余性精简模型，在不影响任务完成度的情况下，得到参数量更少、结构更精简的模型。

介绍了7种技术

| 参数剪枝（压缩模型参数） | 设计关于参数重要性的评价准则，基于该准则判断网络参数的重要程度，删除冗余参数 |
| --- | --- |
| 参数量化（压缩模型参数） | 讲网络参数从32位全精度浮点数量化到更低位数 |
| 低轶分解 （压缩模型参数） | 将高维参数向量降维分解为低维向量 |
| 参数共享（压缩模型参数） | 利用机构化矩阵或聚类方法映射到网络内部参数 |
| 紧凑网络（压缩模型结构） | 从卷积核，特殊层和网络结构3个级别设计新型轻量网络 |
| 知识蒸馏（压缩模型结构） | 将大模型提炼成小模型 |
| 混合方式（） | 前几种方法的组合 |

## 参数剪枝

### **定义**

在预训练模型上，设计针对网络参数的评价标准，以此为根据删除冗余参数

### **分类**

- **非结构化剪枝**
    
    粒度比较细，可以无限制去除网络中期望比例的任何“冗余”参数，不过这样也会带来裁剪后的网络结构不完成，难以加速的问题
    
- **结构化剪枝**
    
    粒度较粗，剪枝的最小单位是filter内参数组合，通过对filter或者feature map来设置评价因子，甚至可以删除整个filter或者几个通道，使得网络变窄。从而可以直接实现加速，但会带来预测精度的下降。
    

## 参数量化

### 定义

使用较低位宽表示32位浮点网络参数。网络参数包括，权重，激活值，梯度和误差。可以使用统一位宽比如（16-bit,8-bit,2-bit,1-bit）

### 特点

- 优点
    - 显著减少参数存储空间与内存占用空间
    - 加快运算速度，降低设备能耗
- 缺点
    - 位宽减少损失了一部分信息量，造成推理精度的下降。
    - 量化

### 二值化

限制网络参数取值为1或-1，极大地降低模型对存储空间和内存空间的需求，并且讲原来的乘法操作转换成加法或移位操作。（速度快但精度下降）

### 三值化

在1，-1的基础上加上0。防止量化误差

### 聚类量化

当参数量大，使用聚类方法进行权重量化

- Kmeans 聚类用于量化全连结层参数
    
    <img src = "https://img-blog.csdnimg.cn/87711ad852f3420f9bb6e4fd5be931af.png">
    
    如图所示，对原始权重聚类形成码本，为权值分配码本中的索引，所以只需存储码本和索引，无需存储原始权重信息。
    

### 混合位宽

> 你们别太离谱我说
> 

根据经验手动选定最优的网络参数位宽组合

### 训练技巧

- 由于量化网络的网络参数不是连续的数值，所以不能像普通的卷积神经网络那样直接使用梯度下降方法进行训练，而需要特殊的方法对这些离散的参数值进行处理，使其不断优化，最终实现训练目。
    1. Zhou 等人[87]提出了一种增量式网络量化方法 INQ。先对权重进行划分，将对预测精度贡献小的权重划入量化组；然后通过再训练恢复性能。
    2. Cai 等人[88]提出了 Halfwave Gaussian quantizer(HWGQ) 方法，设计了两个 ReLU 非线性逼近器(前馈计算中的半波高斯量化器和反向传播的分段连续函数)，以训练低精度的深度学习网络。
    3. Leng 等人[89]提出，利用ADMM[90]解决低位宽网络训练问题。
    4. Zhuang 等人[91]针对低位宽卷积神经网络提出 3 种训练技巧，以期得到较高精度。
    5. Zhou 等人[92]提出一种显式的 loss-error-aware 量化方法，综合考虑优化过程中的 loss 扰动和权值近似误差，采用增量量化策略。
    6. Park 等人[93]提出了价值感知量化方法来降低训练中的内存成本和推理中的计算/内存成本，并且提出一种仅在训练过程中使用量化激活值的量化反向传播方法。
    7. Shayer 等人[94]展示了如何通过对局部再参数化技巧的简单修改，来实现离散权值的训练，该技巧以前用于训练高斯分布权值。
    8. Louizos 等人[95]引入一种可微的量化方法，将网络的权值和激活值的连续分布转化为量化网格上的分类分布，随后被放宽到连续代理，可以允许有效的基于梯度的优化。
    

## 低****秩分解****

### 定义

低秩分解是指通过合并维数和施加低秩约束的方式**稀疏化**卷积核矩阵，由于权值向量大多分布在低秩子空间，所以可以用少数的基向量来重构卷积核矩阵，达到缩小存储空间的目的。

### 特点

低轶分解在大卷积核和中小型网络中都有不错的压缩效果。

## 参数共享

### 定义

利用结构化矩阵或聚类等方法映射网络参数，减少参数数量。

### 特点

参数共享方法的原理和参数剪枝类似，都是利用参数存在大量冗余的特点，目的是为了减少参数量但和直接剪枝不同的是，参数共享设计了**一种映射形式。将**全部参数映射到少量数据上，减少了对存储空间的需求。

缺点是不容易泛化，

## 紧凑网络

### 定义

构造特殊结构的filter，网络层甚至网络

### 特点

从头训练，获得适宜部署到终端设备的网络性能。降低时间成本，具有存储量小，计算量低和网络性能好的特点。

但是，无法和其他压缩方法和加速方法使用，且泛化较差。不适合作为预训练模型

## 知识蒸馏

### 定义

需要两种模型：老师模型和学生模型

### 特点

老师模型通常是大型神经网络模型，将老师模型的softmax层输出作为soft target与学生模型的softmax层输出作为hard target一同送入total loss计算。指导学生模型训练。

将教师模型的知识迁移到学生模型中，使学生模型达到与教师模型相当的性能。学生模型更加紧凑高效，起到模型压缩的目的。知识蒸馏法可使深层网络变浅，极大地降低了计算成本，但也存在其局限性。由于使用 softmax 层输出作为知识，所以一般多用于具有 softmax 损失函数的分类任务，在其他任务的泛化性不好；并且就目前来看，其压缩比与蒸馏后的模型性能还存在较大的进步空间。

<img src = "https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c48fbc5f-cc91-4475-b469-85c4c246d7b6/Untitled.png">